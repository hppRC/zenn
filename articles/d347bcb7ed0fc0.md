---
title: "BERTã®åŸ‹ã‚è¾¼ã¿ç©ºé–“ã®å¯è¦–åŒ–ã‚’æœ€é€Ÿã§"
emoji: "ğŸ‰"
type: "tech"
topics: ["python", "transformers"]
published: true
---

BERTã®token embeddings(å…¥åŠ›éƒ¨åˆ†ã«ã‚ã‚‹å˜èªid->å˜èªåŸ‹ã‚è¾¼ã¿ã«å¤‰æ›ã™ã‚‹å±¤)ã®åŸ‹ã‚è¾¼ã¿ç©ºé–“ã®å¯è¦–åŒ–ã‚’ã‚„ã£ãŸã®ã§ã€æ‰‹é †ã‚’ã¾ã¨ã‚ãŸã€‚
æ–‡è„ˆåŒ–å˜èªåŸ‹ã‚è¾¼ã¿ã®æ–¹(BERTã®å‡ºåŠ›ãƒ™ã‚¯ãƒˆãƒ«)ã®å¯è¦–åŒ–ã‚‚ä¼¼ãŸã‚ˆã†ãªæ‰‹é †ã§ã§ãã‚‹ã¨æ€ã†ã€‚

ä»Šå›ã¯æ±åŒ—å¤§ã®ä¹¾ç ”ã®æ–¹ãŒå…¬é–‹ã•ã‚Œã¦ã„ã‚‹æ—¥æœ¬èªBERT([cl-tohoku/bert-base-japanese-whole-word-masking](https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking?text=æ±åŒ—å¤§å­¦ã§%5BMASK%5Dã®ç ”ç©¶ã‚’ã—ã¦ã„ã¾ã™%E3%80%82))ã‚’åˆ©ç”¨ã—ãŸã€‚

ä½¿ç”¨ã™ã‚‹æŠ€è¡“ã¯ä¸»ã«ä»¥ä¸‹ã€‚
- huggingface/transformers: äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®åˆ©ç”¨
- holoviews: å¯è¦–åŒ–ã¾ã¨ã‚ãƒ„ãƒ¼ãƒ«
- t-SNE: æ¬¡å…ƒå‰Šæ¸›
- poetry: ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒãƒãƒ¼ã‚¸ãƒ£


# ç’°å¢ƒæ§‹ç¯‰

poetryã§ã„ã„æ„Ÿã˜ã«ã‚„ã£ãŸã€‚
ä»¥ä¸‹ã®`pyproject.toml`ã‚’ã‚³ãƒ”ãƒšã—ã¦`poetry install`ã™ã‚Œã°ã‚ˆã•ãã†ã€‚

```toml
[tool.poetry]
name = "hoge"
version = "0.1.0"
description = ""
authors = ["hogefuga"]

[tool.poetry.dependencies]
python = "^3.8"
transformers = "^4.6.1"
torch = "^1.8.1"
holoviews = {extras = ["recommended"], version = "^1.14.4"}
numpy = "^1.20.3"
param = "^1.10.1"
matplotlib = "^3.4.2"
bokeh = "^2.3.2"
plotly = "^4.14.3"
fugashi = {extras = ["unidic-lite"], version = "^1.1.0"}
jupyter = "^1.0.0"
ipadic = "^1.0.0"
sklearn = "^0.0"

[tool.poetry.dev-dependencies]

[build-system]
requires = ["poetry>=0.12"]
build-backend = "poetry.masonry.api"
```


# ã‚³ãƒ¼ãƒ‰

çµæ§‹å˜ç´”ãªã“ã¨ã—ã‹ã‚„ã£ã¦ã„ãªã„ãŒã€æµã‚Œã¨ã—ã¦ã¯

1. æ±åŒ—å¤§ã®æ—¥æœ¬èªBERTã®ãƒ¢ãƒ‡ãƒ«ã¨tokenizerã‚’ãƒ­ãƒ¼ãƒ‰
2. `model.get_input_embeddings()`ã§ `nn.Embedding`ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒå–ã‚Œã‚‹ã®ã§ã€ãã“ã‹ã‚‰`torch.Tensor`ã‚’ä½œã‚‹ã€‚
3. `tokenizer.get_vocab()`ã§è¾æ›¸ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å–å¾—
4. ãƒ™ã‚¯ãƒˆãƒ«ã®ãƒªã‚¹ãƒˆãªã‚Šè¾æ›¸ãªã‚Šä½•ã‹ã«ã™ã‚‹
5. t-SNEã®è¨­å®šã‚’ã—ã¦ã€å°„å½±ã™ã‚‹(æ±åŒ—å¤§BERTã®èªå½™ã‚µã‚¤ã‚ºã¯32000ãªã®ã§ã€å…¨éƒ¨ã‚„ã‚‹ã¨è¶…é‡ã„ãŸã‚ä»Šå›ã¯é »åº¦é †ä¸Šä½3000å€‹)
6. holoviewsã®è¨­å®šã‚’ã—ã¦ã€ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã«ã‚°ãƒ©ãƒ•ã‚’è¦‹ãŸã„ã®ã§`plotly`ã®è¨­å®šã‚’ã—ã¤ã¤ã‚°ãƒ©ãƒ•ã‚’æç”»ã™ã‚‹ã€‚


```python
# %%
import torch
from transformers import AutoModel, AutoTokenizer


# %%
tokenizer = AutoTokenizer.from_pretrained("cl-tohoku/bert-base-japanese-whole-word-masking")
model = AutoModel.from_pretrained("cl-tohoku/bert-base-japanese-whole-word-masking")


# %%
token_embeddings = model.get_input_embeddings().weight.clone()
vocab = tokenizer.get_vocab()
vectors = {}


# %%
for idx in vocab.values():
    vectors[idx] = token_embeddings[idx].detach().numpy().copy()


# %%
from sklearn.manifold import TSNE
tsne = TSNE(n_components=2, random_state=0)


# %%
reduced_vectors = tsne.fit_transform(list(vectors.values())[:3000])


# %%
import holoviews as hv
from holoviews import opts

hv.extension('plotly')


# %%
points = hv.Points(reduced_vectors)
labels = hv.Labels({('x', 'y'): reduced_vectors, 'text': [token for token, _ in zip(vocab, reduced_vectors)]}, ['x', 'y'], 'text')

(points * labels).opts(
    opts.Labels(xoffset=0.05, yoffset=0.05, size=14, padding=0.2, width=1500, height=1000),
    opts.Points(color='black', marker='x', size=3),
)
```

# å®Ÿé¨“çµæœ

çµæœã¨ã—ã¦ã¯ä»¥ä¸‹ã®é€šã‚Šã€‚
çµæ§‹BERTã®token embeddingsã£ã¦ã¾ã¨ã‚‚ãªã‚“ã ãªã¨ã„ã†æ°—æŒã¡ã«ãªã£ãŸã€‚
ã“ã‚Œæ–‡è„ˆåŒ–å˜èªåŸ‹ã‚è¾¼ã¿(contextualized word embeddings, BERTã®Transformer Stackã‹ã‚‰å‡ºåŠ›ã•ã‚Œã‚‹æ–¹)ã˜ã‚ƒãªã„ã®ã§ã€ãã®ç‚¹ã ã‘ã”æ³¨æ„ã‚’ã€‚
å¤§ä½“åŒã˜ç©ºé–“ã‚’æ§‹æˆã™ã‚‹ã¨æ€ã†ã‘ã©ã€‚
(èª°ã‹æ–‡è„ˆåŒ–å˜èªåŸ‹ã‚è¾¼ã¿ã®æ–¹ã§æ¤œè¨¼ã—ã¦ãã‚ŒãŸã‚‰å–œã³ã¾ã™)

![](https://storage.googleapis.com/zenn-user-upload/dc8c33ffbbcfd0ca791041d1.png)


å¤§ããªå›³ã‚’è¦‹ã¦ã‚‚ã‚ˆãã‚ã‹ã‚‰ãªã„ã®ã§ã‚‚ã£ã¨ã‚ºãƒ¼ãƒ ã—ãŸå›³ã‚’è¦‹ã¦ã¿ã‚‹ã€‚

![](https://storage.googleapis.com/zenn-user-upload/f56b103f50f25bc8586b6125.png)

ä¸Šå›³ã‚’è¦‹ã‚‹ã¨ã€ä¾‹ãˆã°ã€Œå„ªå‹ã€ã€Œãƒãƒ£ãƒ³ãƒ”ã‚ªãƒ³ã€ã€Œå‹åˆ©ã€ã‚„ã€Œæ”¹é©ã€ã€Œæ”¹æ­£ã€ã€Œå¤‰åŒ–ã€ã€ã€Œç ”ç©¶ã€ã€Œèª¿æŸ»ã€ã®ã‚ˆã†ãªã€æ„å‘³çš„ã«è¿‘ã„å˜èªãŒåŸ‹ã‚è¾¼ã¿ç©ºé–“ä¸Šã§ã‚‚è¿‘ãã«åˆ†å¸ƒã—ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚

ä»–ã®éƒ¨åˆ†ã‚‚è¦‹ã¦ã¿ã‚‹ã€‚

![](https://storage.googleapis.com/zenn-user-upload/4e40c7c3ecce8f322aedfdd3.png)

ä¸Šå›³ã‚’è¦‹ã‚‹ã¨ã€ä¾‹ãˆã°æ•°å­—(0~9ã¨ã‹ã¾ã‚æ•°å­—å…¨èˆ¬)ã€è¨˜å·(symbol)ãŒå›ºã¾ã£ã¦ãŸã‚Šã€å³ä¸‹ã«å…ƒå·ãŒå›ºã¾ã£ã¦ã„ãŸã‚Šã™ã‚‹ã€‚

ã•ã‚‰ã«ä»–ã®éƒ¨åˆ†ã‚‚è¦‹ã¦ã¿ã‚‹ã€‚

![](https://storage.googleapis.com/zenn-user-upload/70dbde77135315e989f565a6.png)

ä¸Šå›³ã‚’è¦‹ã‚‹ã¨ã€ä¸­å¿ƒã«å›½åãŒå›ºã¾ã£ã¦ã„ã¦ã€ãã®è¿‘ãã«æ—¥æœ¬ã®åœ°åã‚¯ãƒ©ã‚¹ã‚¿ãŒã§ãã¦ã„ãã†ãªã“ã¨ãŒã‚ã‹ã‚‹ã€‚
ã¾ãŸã€å³ä¸Šã«æ•°é‡å˜ä½ã‚¯ãƒ©ã‚¹ã‚¿ãŒã‚ã‚Šãã†ã€‚

ã¨ã‚Šã‚ãˆãšã¯ã“ã‚“ãªã¨ã“ã‚ã§ã€é »åº¦é †ä¸Šä½3000èª(ã‚µãƒ–ãƒ¯ãƒ¼ãƒ‰)ã˜ã‚ƒãªãã¦ã€ã‚‚ã£ã¨å¤šãã‚’è¦‹ã¦ã¿ãŸã‚Šã€é »åº¦é †ä¸‹ä½ã‹ã‚‰ã¿ãŸã‚Šã™ã‚‹ã®ã‚‚ã„ã„ã¨æ€ã†ã€‚
è‹±èªBERTã‚„ãã®ä»–ã®RoBERTaã¨ã‹ã®åŸ‹ã‚è¾¼ã¿ç©ºé–“ã‚’è¦‹ã¦ã‚‚é¢ç™½ã„ã¨æ€ã†ã—ã€GPT-2ã¨ã‹AutoRegressiveãªãƒ¢ãƒ‡ãƒ«ã®åŸ‹ã‚è¾¼ã¿ç©ºé–“ã‚’è¦‹ã¦ã‚‚é¢ç™½ã„ã¨æ€ã†ã€‚

ä½•ã‹è³ªå•ãŒã‚ã‚Œã° [@hpp_ricecake](https://twitter.com/hpp_ricecake)ã¾ã§ãªã‚“ã§ã‚‚ã©ã†ãï¼

å†ç¾å®Ÿé¨“ç”¨ã®ç’°å¢ƒæ§‹ç¯‰ç”¨ã‚³ãƒ¼ãƒ‰ã¯ã“ã®[ãƒªãƒã‚¸ãƒˆãƒª](https://github.com/hppRC/visualize-token-embeddings)ã‚’å‚ç…§ãã ã•ã„ã€‚



@[tweet](https://twitter.com/hpp_ricecake/status/1400110557097693185?s=21)


## è¿½è¨˜: è‹±èªã®BERTã«ã¤ã„ã¦ã‚‚ã‚„ã£ã¦ã¿ãŸ

@[tweet](https://twitter.com/hpp_ricecake/status/1400427242879012864?s=21)

çµæ§‹ä¸æ€è­°ãªåˆ†å¸ƒã‚’ã—ã¦ã„ã¦ãŠã‚‚ã—ã‚ã„ã€‚
ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã¯[bert-base-uncased](https://huggingface.co/bert-base-uncased)ã€‚



@[tweet](https://twitter.com/hpp_ricecake/status/1400427242879012864?s=21)